\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\babel@aux{english}{}
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{Abbildungsverzeichnis}{IV}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Tabellenverzeichnis}{V}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Abkürzungsverzeichnis}{VI}{Doc-Start}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{GlobalRisksReport2024}
\abx@aux@segm{0}{0}{GlobalRisksReport2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{GlobalRisksReport2024}
\abx@aux@segm{0}{0}{GlobalRisksReport2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Taman2024}
\abx@aux@segm{0}{0}{Taman2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\abx@aux@cite{0}{Sharafaldin2018}
\abx@aux@segm{0}{0}{Sharafaldin2018}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation und Problemstellung}{1}{subsection.1.1}\protected@file@percent }
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\abx@aux@page{4}{1}
\abx@aux@page{5}{1}
\abx@aux@page{6}{1}
\abx@aux@page{7}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Forschungsfrage und Zielsetzung}{1}{subsection.1.2}\protected@file@percent }
\abx@aux@page{8}{1}
\abx@aux@page{9}{1}
\abx@aux@page{10}{1}
\abx@aux@page{11}{1}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{McHugh2000}
\abx@aux@segm{0}{0}{McHugh2000}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Aufbau der Arbeit}{2}{subsection.1.3}\protected@file@percent }
\abx@aux@page{12}{2}
\abx@aux@page{13}{2}
\abx@aux@page{14}{2}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretische Fundierung}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Grundlagen der Netzwerk-Anomalieerkennung und Intrusion Detection Systems}{3}{subsection.2.1}\protected@file@percent }
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\abx@aux@page{18}{3}
\abx@aux@page{19}{3}
\abx@aux@page{20}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Traditionelle versus Machine Learning-basierte Detektionsansätze}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Machine Learning-Taxonomie für Anomalieerkennung}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Transfer Learning und Cross-Dataset-Generalisierung}{3}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodik}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Daten}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Modelle und Hyperparameter}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Beispielhafte Hyperparameter.}}{4}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:hyper}{{1}{4}{Beispielhafte Hyperparameter}{table.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Ergebnisse}{5}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot).}}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:performance_comparison}{{1}{5}{Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot)}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence.}}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig:transfer_analysis}{{2}{6}{Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence}{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Machine Learning Models Performance Comparison on NSL-KDD Dataset}}{6}{table.caption.4}\protected@file@percent }
\newlabel{tab:model_performance}{{2}{6}{Machine Learning Models Performance Comparison on NSL-KDD Dataset}{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05).}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig:dataset_overview}{{3}{7}{Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05)}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{8}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Fazit}{9}{section.6}\protected@file@percent }
\abx@aux@page{21}{10}
\abx@aux@page{22}{10}
\abx@aux@page{23}{10}
\abx@aux@page{24}{10}
\abx@aux@page{25}{10}
\abx@aux@page{26}{10}
\abx@aux@page{27}{10}
\abx@aux@page{28}{10}
\abx@aux@page{29}{10}
\abx@aux@page{30}{10}
\abx@aux@page{31}{10}
\abx@aux@page{32}{10}
\@writefile{toc}{\contentsline {section}{Anhangsverzeichnis}{11}{section.6}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\@writefile{toc}{\contentsline {section}{\numberline {A}Dataset-Charakterisierung und Explorative Analyse}{12}{appendix.A}\protected@file@percent }
\newlabel{app:dataset_analysis}{{A}{12}{Dataset-Charakterisierung und Explorative Analyse}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}NSL-KDD Attack Distribution}{12}{subsection.A.1}\protected@file@percent }
\newlabel{app:nsl_attack_dist}{{A.1}{12}{NSL-KDD Attack Distribution}{subsection.A.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle.}}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:nsl_attack_dist}{{4}{12}{NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation der Attack-Verteilung}{12}{paragraph*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}CIC-IDS-2017 Attack Distribution}{13}{subsection.A.2}\protected@file@percent }
\newlabel{app:cic_attack_dist}{{A.2}{13}{CIC-IDS-2017 Attack Distribution}{subsection.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD.}}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig:cic_attack_dist}{{5}{13}{CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Unterschiede zu NSL-KDD}{13}{paragraph*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Dataset Comparison Overview}{14}{subsection.A.3}\protected@file@percent }
\newlabel{app:dataset_comparison}{{A.3}{14}{Dataset Comparison Overview}{subsection.A.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148).}}{14}{figure.caption.10}\protected@file@percent }
\newlabel{fig:app_dataset_comparison}{{6}{14}{Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148)}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Within-Dataset Performance Details}{15}{appendix.B}\protected@file@percent }
\newlabel{app:within_dataset}{{B}{15}{Within-Dataset Performance Details}{appendix.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}NSL-KDD ROC-Kurven}{15}{subsection.B.1}\protected@file@percent }
\newlabel{app:nsl_roc}{{B.1}{15}{NSL-KDD ROC-Kurven}{subsection.B.1}{}}
\newlabel{fig:nsl_roc_baseline}{{7a}{15}{Baseline-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{sub@fig:nsl_roc_baseline}{{a}{15}{Baseline-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{fig:nsl_roc_advanced}{{7b}{15}{Advanced-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{sub@fig:nsl_roc_advanced}{{b}{15}{Advanced-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5).}}{15}{figure.caption.11}\protected@file@percent }
\newlabel{fig:app_nsl_roc}{{7}{15}{ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5)}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{ROC-Interpretation}{15}{paragraph*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}CIC-IDS-2017 ROC-Kurven}{16}{subsection.B.2}\protected@file@percent }
\newlabel{app:cic_roc}{{B.2}{16}{CIC-IDS-2017 ROC-Kurven}{subsection.B.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren).}}{16}{figure.caption.13}\protected@file@percent }
\newlabel{fig:app_cic_roc}{{8}{16}{ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren)}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Precision-Recall Kurven}{17}{subsection.B.3}\protected@file@percent }
\newlabel{app:pr_curves}{{B.3}{17}{Precision-Recall Kurven}{subsection.B.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen.}}{17}{figure.caption.14}\protected@file@percent }
\newlabel{fig:app_pr_curves}{{9}{17}{Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{PR-Kurven vs. ROC-Kurven}{17}{paragraph*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Konfusionsmatrizen NSL-KDD}{18}{subsection.B.4}\protected@file@percent }
\newlabel{app:cm_nsl}{{B.4}{18}{Konfusionsmatrizen NSL-KDD}{subsection.B.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte).}}{18}{figure.caption.16}\protected@file@percent }
\newlabel{fig:app_cm_nsl}{{10}{18}{Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte)}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.5}Konfusionsmatrizen CIC-IDS-2017}{18}{subsection.B.5}\protected@file@percent }
\newlabel{app:cm_cic}{{B.5}{18}{Konfusionsmatrizen CIC-IDS-2017}{subsection.B.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0).}}{18}{figure.caption.17}\protected@file@percent }
\newlabel{fig:app_cm_cic}{{11}{18}{Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0)}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Cross-Validation und Statistische Analysen}{19}{appendix.C}\protected@file@percent }
\newlabel{app:cross_validation}{{C}{19}{Cross-Validation und Statistische Analysen}{appendix.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Cross-Validation Vergleich}{19}{subsection.C.1}\protected@file@percent }
\newlabel{app:cv_comparison}{{C.1}{19}{Cross-Validation Vergleich}{subsection.C.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds.}}{19}{figure.caption.18}\protected@file@percent }
\newlabel{fig:app_cv_comparison}{{12}{19}{Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}CV Results Distribution}{20}{subsection.C.2}\protected@file@percent }
\newlabel{app:cv_boxplot}{{C.2}{20}{CV Results Distribution}{subsection.C.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83).}}{20}{figure.caption.19}\protected@file@percent }
\newlabel{fig:app_cv_boxplot}{{13}{20}{Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83)}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {paragraph}{Variabilitäts-Interpretation}{20}{paragraph*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Statistische Vergleichsanalysen}{21}{subsection.C.3}\protected@file@percent }
\newlabel{app:statistical_comparison}{{C.3}{21}{Statistische Vergleichsanalysen}{subsection.C.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05).}}{21}{figure.caption.21}\protected@file@percent }
\newlabel{fig:app_statistical}{{14}{21}{Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05)}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Signifikanz-Befunde}{21}{paragraph*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Konvergenzanalyse}{22}{subsection.C.4}\protected@file@percent }
\newlabel{app:convergence}{{C.4}{22}{Konvergenzanalyse}{subsection.C.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean.}}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:app_convergence}{{15}{22}{Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Konvergenz-Interpretation}{22}{paragraph*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D}Cross-Dataset Transfer und Generalisierung}{23}{appendix.D}\protected@file@percent }
\newlabel{app:transfer_analysis}{{D}{23}{Cross-Dataset Transfer und Generalisierung}{appendix.D}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Cross-Dataset Transfer Confusion Matrices}{23}{subsection.D.1}\protected@file@percent }
\newlabel{app:transfer_cm}{{D.1}{23}{Cross-Dataset Transfer Confusion Matrices}{subsection.D.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431).}}{23}{figure.caption.25}\protected@file@percent }
\newlabel{fig:app_transfer_cm}{{16}{23}{Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431)}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Transfer-Pattern-Analyse}{23}{paragraph*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Harmonisierte Evaluation}{24}{subsection.D.2}\protected@file@percent }
\newlabel{app:harmonized}{{D.2}{24}{Harmonisierte Evaluation}{subsection.D.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten).}}{24}{figure.caption.27}\protected@file@percent }
\newlabel{fig:app_harmonized}{{17}{24}{Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten)}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Harmonisierungs-Effekte}{24}{paragraph*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}Learning Curves und Trainingsanalysen}{25}{appendix.E}\protected@file@percent }
\newlabel{app:learning_curves}{{E}{25}{Learning Curves und Trainingsanalysen}{appendix.E}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Model Learning Curves}{25}{subsection.E.1}\protected@file@percent }
\newlabel{app:learning_curves_detail}{{E.1}{25}{Model Learning Curves}{subsection.E.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen.}}{25}{figure.caption.29}\protected@file@percent }
\newlabel{fig:app_learning_curves}{{18}{25}{Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Lernkurven-Interpretation}{25}{paragraph*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Praktische Implikationen}{26}{paragraph*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {F}Computational Efficiency Analysis}{27}{appendix.F}\protected@file@percent }
\newlabel{app:efficiency}{{F}{27}{Computational Efficiency Analysis}{appendix.F}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F.1}Timing Performance Analysis}{27}{subsection.F.1}\protected@file@percent }
\newlabel{app:timing_analysis}{{F.1}{27}{Timing Performance Analysis}{subsection.F.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time).}}{27}{figure.caption.32}\protected@file@percent }
\newlabel{fig:app_timing}{{19}{27}{Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time)}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Effizienz-Ranking}{27}{paragraph*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reverse-Transfer Performance-Paradox}{27}{paragraph*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {F.2}Real-World Deployment Considerations}{28}{subsection.F.2}\protected@file@percent }
\newlabel{app:deployment}{{F.2}{28}{Real-World Deployment Considerations}{subsection.F.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Deployment-Szenarien und Modellempfehlungen}}{28}{table.caption.35}\protected@file@percent }
\newlabel{tab:deployment}{{3}{28}{Deployment-Szenarien und Modellempfehlungen}{table.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Comprehensive Model Dashboard}{29}{appendix.G}\protected@file@percent }
\newlabel{app:dashboard}{{G}{29}{Comprehensive Model Dashboard}{appendix.G}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum.}}{29}{figure.caption.36}\protected@file@percent }
\newlabel{fig:app_dashboard}{{20}{29}{Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Cluster-Analyse-Befunde}{29}{paragraph*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Nützliche LaTeX-Referenz}{30}{paragraph*.37}\protected@file@percent }
\newlabel{lst:fib}{{1}{33}{Fibonacci-Beispiel}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Fibonacci-Beispiel}}{33}{lstlisting.1}\protected@file@percent }
\newlabel{lst:mini}{{2}{33}{Minimalbeispiel}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces Minimalbeispiel}}{33}{lstlisting.2}\protected@file@percent }
\expandafter\ifx\csname c@figure@totc\endcsname\relax\newcounter{figure@totc}\fi\setcounter{figure@totc}{20}
\expandafter\ifx\csname c@table@totc\endcsname\relax\newcounter{table@totc}\fi\setcounter{table@totc}{3}
\abx@aux@read@bbl@mdfivesum{2F063B767018B3CC0EF39B0C86AE4F64}
\abx@aux@defaultrefcontext{0}{Belavagi2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{CICIDS2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{NSLKDD2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gharib2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{McHugh2000}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Mourouzis2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Ring2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Sharafaldin2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Taman2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Tavallaee2009}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Vinayakumar2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{GlobalRisksReport2024}{nyt/global//global/global}
\gdef \@abspage@last{41}
