\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\babel@aux{english}{}
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{Abbildungsverzeichnis}{IV}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Abkürzungsverzeichnis}{V}{Doc-Start}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{GlobalRisksReport2024}
\abx@aux@segm{0}{0}{GlobalRisksReport2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Taman2024}
\abx@aux@segm{0}{0}{Taman2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{McHugh2000}
\abx@aux@segm{0}{0}{McHugh2000}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation und Problemstellung}{1}{subsection.1.1}\protected@file@percent }
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\abx@aux@page{4}{1}
\abx@aux@page{5}{1}
\abx@aux@page{6}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Forschungsfrage und Zielsetzung}{1}{subsection.1.2}\protected@file@percent }
\abx@aux@page{7}{1}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Aufbau der Arbeit}{2}{subsection.1.3}\protected@file@percent }
\abx@aux@page{8}{2}
\abx@aux@page{9}{2}
\abx@aux@page{10}{2}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretische Fundierung}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Grundlagen der Netzwerk-Anomalieerkennung und Intrusion Detection Systems}{3}{subsection.2.1}\protected@file@percent }
\abx@aux@page{11}{3}
\abx@aux@page{12}{3}
\abx@aux@page{13}{3}
\abx@aux@page{14}{3}
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\abx@aux@page{18}{3}
\abx@aux@page{19}{3}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Bishop2006}
\abx@aux@segm{0}{0}{Bishop2006}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Bishop2006}
\abx@aux@segm{0}{0}{Bishop2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Traditionelle versus Machine Learning-basierte Detektionsansätze}{4}{subsection.2.2}\protected@file@percent }
\abx@aux@page{20}{4}
\abx@aux@page{21}{4}
\abx@aux@page{22}{4}
\abx@aux@page{23}{4}
\abx@aux@page{24}{4}
\abx@aux@page{25}{4}
\abx@aux@page{26}{4}
\abx@aux@page{27}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Machine Learning-Taxonomie für Anomalieerkennung}{4}{subsection.2.3}\protected@file@percent }
\abx@aux@page{28}{4}
\abx@aux@page{29}{4}
\abx@aux@page{30}{4}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Bishop2006}
\abx@aux@segm{0}{0}{Bishop2006}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Platt1999}
\abx@aux@segm{0}{0}{Platt1999}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Zhou2020}
\abx@aux@segm{0}{0}{Zhou2020}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Sharafaldin2018}
\abx@aux@segm{0}{0}{Sharafaldin2018}
\abx@aux@page{31}{5}
\abx@aux@page{32}{5}
\abx@aux@page{33}{5}
\abx@aux@page{34}{5}
\abx@aux@page{35}{5}
\abx@aux@page{36}{5}
\abx@aux@page{37}{5}
\abx@aux@page{38}{5}
\abx@aux@page{39}{5}
\abx@aux@page{40}{5}
\abx@aux@page{41}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feature Engineering und Datenvorverarbeitung}{5}{subsection.2.4}\protected@file@percent }
\abx@aux@page{42}{5}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Bishop2006}
\abx@aux@segm{0}{0}{Bishop2006}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@page{43}{6}
\abx@aux@page{44}{6}
\abx@aux@page{45}{6}
\abx@aux@page{46}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Transfer Learning und Cross-Dataset-Generalisierung}{6}{subsection.2.5}\protected@file@percent }
\abx@aux@page{47}{6}
\abx@aux@page{48}{6}
\abx@aux@page{49}{6}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Tavallaee2009}
\abx@aux@segm{0}{0}{Tavallaee2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Evaluationsmetriken und Cross-Dataset-Transferierbarkeit}{7}{subsection.2.6}\protected@file@percent }
\abx@aux@page{50}{7}
\abx@aux@page{51}{7}
\abx@aux@page{52}{7}
\abx@aux@page{53}{7}
\abx@aux@page{54}{7}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Tavallaee2009}
\abx@aux@segm{0}{0}{Tavallaee2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodik}{8}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Forschungsdesign und methodische Begründung}{8}{subsection.3.1}\protected@file@percent }
\abx@aux@page{55}{8}
\abx@aux@page{56}{8}
\abx@aux@page{57}{8}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Tavallaee2009}
\abx@aux@segm{0}{0}{Tavallaee2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{McHugh2000}
\abx@aux@segm{0}{0}{McHugh2000}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Sharafaldin2018}
\abx@aux@segm{0}{0}{Sharafaldin2018}
\abx@aux@page{58}{9}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Datengrundlage und Stichprobenauswahl}{9}{subsection.3.2}\protected@file@percent }
\abx@aux@page{59}{9}
\abx@aux@page{60}{9}
\abx@aux@page{61}{9}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experimenteller Ablauf und Evaluationsframework}{10}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Feature-Engineering und Harmonisierung}{10}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Modellauswahl und Hyperparameter-Konfiguration}{10}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Evaluationsmetriken und Transfer-Learning-Assessment}{10}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Experimentelle Kontrolle und Qualitätssicherung}{10}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Memory-Adaptation und Computational Challenges}{10}{subsection.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Methodische Abgrenzungen und wissenschaftliche Limitationen}{10}{subsection.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Ergebnisse}{11}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot).}}{11}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:performance_comparison}{{1}{11}{Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot)}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence.}}{12}{figure.caption.2}\protected@file@percent }
\newlabel{fig:transfer_analysis}{{2}{12}{Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence}{figure.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Top-22 Machine Learning Models Performance Ranking: NSL-KDD Dataset}}{12}{table.caption.3}\protected@file@percent }
\newlabel{tab:model_performance}{{1}{12}{Top-22 Machine Learning Models Performance Ranking: NSL-KDD Dataset}{table.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05).}}{13}{figure.caption.4}\protected@file@percent }
\newlabel{fig:dataset_overview}{{3}{13}{Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05)}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{14}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Fazit}{15}{section.6}\protected@file@percent }
\abx@aux@page{62}{16}
\abx@aux@page{63}{16}
\abx@aux@page{64}{16}
\abx@aux@page{65}{16}
\abx@aux@page{66}{16}
\abx@aux@page{67}{16}
\abx@aux@page{68}{16}
\abx@aux@page{69}{16}
\abx@aux@page{70}{16}
\abx@aux@page{71}{16}
\abx@aux@page{72}{16}
\abx@aux@page{73}{16}
\abx@aux@page{74}{16}
\abx@aux@page{75}{17}
\abx@aux@page{76}{17}
\abx@aux@page{77}{17}
\abx@aux@page{78}{17}
\@writefile{toc}{\contentsline {section}{Anhangsverzeichnis}{18}{section.6}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\@writefile{toc}{\contentsline {section}{\numberline {A}Dataset-Charakterisierung und Explorative Analyse}{19}{appendix.A}\protected@file@percent }
\newlabel{app:dataset_analysis}{{A}{19}{Dataset-Charakterisierung und Explorative Analyse}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}NSL-KDD Attack Distribution}{19}{subsection.A.1}\protected@file@percent }
\newlabel{app:nsl_attack_dist}{{A.1}{19}{NSL-KDD Attack Distribution}{subsection.A.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle.}}{19}{figure.caption.5}\protected@file@percent }
\newlabel{fig:nsl_attack_dist}{{4}{19}{NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation der Attack-Verteilung}{19}{paragraph*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}CIC-IDS-2017 Attack Distribution}{20}{subsection.A.2}\protected@file@percent }
\newlabel{app:cic_attack_dist}{{A.2}{20}{CIC-IDS-2017 Attack Distribution}{subsection.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD.}}{20}{figure.caption.7}\protected@file@percent }
\newlabel{fig:cic_attack_dist}{{5}{20}{CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Unterschiede zu NSL-KDD}{20}{paragraph*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Dataset Comparison Overview}{21}{subsection.A.3}\protected@file@percent }
\newlabel{app:dataset_comparison}{{A.3}{21}{Dataset Comparison Overview}{subsection.A.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148).}}{21}{figure.caption.9}\protected@file@percent }
\newlabel{fig:app_dataset_comparison}{{6}{21}{Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148)}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Within-Dataset Performance Details}{22}{appendix.B}\protected@file@percent }
\newlabel{app:within_dataset}{{B}{22}{Within-Dataset Performance Details}{appendix.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}NSL-KDD ROC-Kurven}{22}{subsection.B.1}\protected@file@percent }
\newlabel{app:nsl_roc}{{B.1}{22}{NSL-KDD ROC-Kurven}{subsection.B.1}{}}
\newlabel{fig:nsl_roc_baseline}{{7a}{22}{Baseline-Modelle (6 Algorithmen)}{figure.caption.10}{}}
\newlabel{sub@fig:nsl_roc_baseline}{{a}{22}{Baseline-Modelle (6 Algorithmen)}{figure.caption.10}{}}
\newlabel{fig:nsl_roc_advanced}{{7b}{22}{Advanced-Modelle (6 Algorithmen)}{figure.caption.10}{}}
\newlabel{sub@fig:nsl_roc_advanced}{{b}{22}{Advanced-Modelle (6 Algorithmen)}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5).}}{22}{figure.caption.10}\protected@file@percent }
\newlabel{fig:app_nsl_roc}{{7}{22}{ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5)}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{ROC-Interpretation}{22}{paragraph*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}CIC-IDS-2017 ROC-Kurven}{23}{subsection.B.2}\protected@file@percent }
\newlabel{app:cic_roc}{{B.2}{23}{CIC-IDS-2017 ROC-Kurven}{subsection.B.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren).}}{23}{figure.caption.12}\protected@file@percent }
\newlabel{fig:app_cic_roc}{{8}{23}{ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren)}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Precision-Recall Kurven}{24}{subsection.B.3}\protected@file@percent }
\newlabel{app:pr_curves}{{B.3}{24}{Precision-Recall Kurven}{subsection.B.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen.}}{24}{figure.caption.13}\protected@file@percent }
\newlabel{fig:app_pr_curves}{{9}{24}{Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {paragraph}{PR-Kurven vs. ROC-Kurven}{24}{paragraph*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Konfusionsmatrizen NSL-KDD}{25}{subsection.B.4}\protected@file@percent }
\newlabel{app:cm_nsl}{{B.4}{25}{Konfusionsmatrizen NSL-KDD}{subsection.B.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte).}}{25}{figure.caption.15}\protected@file@percent }
\newlabel{fig:app_cm_nsl}{{10}{25}{Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte)}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.5}Konfusionsmatrizen CIC-IDS-2017}{25}{subsection.B.5}\protected@file@percent }
\newlabel{app:cm_cic}{{B.5}{25}{Konfusionsmatrizen CIC-IDS-2017}{subsection.B.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0).}}{25}{figure.caption.16}\protected@file@percent }
\newlabel{fig:app_cm_cic}{{11}{25}{Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0)}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Cross-Validation und Statistische Analysen}{26}{appendix.C}\protected@file@percent }
\newlabel{app:cross_validation}{{C}{26}{Cross-Validation und Statistische Analysen}{appendix.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Cross-Validation Vergleich}{26}{subsection.C.1}\protected@file@percent }
\newlabel{app:cv_comparison}{{C.1}{26}{Cross-Validation Vergleich}{subsection.C.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds.}}{26}{figure.caption.17}\protected@file@percent }
\newlabel{fig:app_cv_comparison}{{12}{26}{Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}CV Results Distribution}{27}{subsection.C.2}\protected@file@percent }
\newlabel{app:cv_boxplot}{{C.2}{27}{CV Results Distribution}{subsection.C.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83).}}{27}{figure.caption.18}\protected@file@percent }
\newlabel{fig:app_cv_boxplot}{{13}{27}{Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83)}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Variabilitäts-Interpretation}{27}{paragraph*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Statistische Vergleichsanalysen}{28}{subsection.C.3}\protected@file@percent }
\newlabel{app:statistical_comparison}{{C.3}{28}{Statistische Vergleichsanalysen}{subsection.C.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05).}}{28}{figure.caption.20}\protected@file@percent }
\newlabel{fig:app_statistical}{{14}{28}{Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05)}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {paragraph}{Signifikanz-Befunde}{28}{paragraph*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Konvergenzanalyse}{29}{subsection.C.4}\protected@file@percent }
\newlabel{app:convergence}{{C.4}{29}{Konvergenzanalyse}{subsection.C.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean.}}{29}{figure.caption.22}\protected@file@percent }
\newlabel{fig:app_convergence}{{15}{29}{Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{Konvergenz-Interpretation}{29}{paragraph*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D}Cross-Dataset Transfer und Generalisierung}{30}{appendix.D}\protected@file@percent }
\newlabel{app:transfer_analysis}{{D}{30}{Cross-Dataset Transfer und Generalisierung}{appendix.D}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Cross-Dataset Transfer Confusion Matrices}{30}{subsection.D.1}\protected@file@percent }
\newlabel{app:transfer_cm}{{D.1}{30}{Cross-Dataset Transfer Confusion Matrices}{subsection.D.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431).}}{30}{figure.caption.24}\protected@file@percent }
\newlabel{fig:app_transfer_cm}{{16}{30}{Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431)}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Transfer-Pattern-Analyse}{30}{paragraph*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Harmonisierte Evaluation}{31}{subsection.D.2}\protected@file@percent }
\newlabel{app:harmonized}{{D.2}{31}{Harmonisierte Evaluation}{subsection.D.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten).}}{31}{figure.caption.26}\protected@file@percent }
\newlabel{fig:app_harmonized}{{17}{31}{Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten)}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {paragraph}{Harmonisierungs-Effekte}{31}{paragraph*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}Learning Curves und Trainingsanalysen}{32}{appendix.E}\protected@file@percent }
\newlabel{app:learning_curves}{{E}{32}{Learning Curves und Trainingsanalysen}{appendix.E}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Model Learning Curves}{32}{subsection.E.1}\protected@file@percent }
\newlabel{app:learning_curves_detail}{{E.1}{32}{Model Learning Curves}{subsection.E.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen.}}{32}{figure.caption.28}\protected@file@percent }
\newlabel{fig:app_learning_curves}{{18}{32}{Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {paragraph}{Lernkurven-Interpretation}{32}{paragraph*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Praktische Implikationen}{33}{paragraph*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {F}Computational Efficiency Analysis}{34}{appendix.F}\protected@file@percent }
\newlabel{app:efficiency}{{F}{34}{Computational Efficiency Analysis}{appendix.F}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F.1}Timing Performance Analysis}{34}{subsection.F.1}\protected@file@percent }
\newlabel{app:timing_analysis}{{F.1}{34}{Timing Performance Analysis}{subsection.F.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time).}}{34}{figure.caption.31}\protected@file@percent }
\newlabel{fig:app_timing}{{19}{34}{Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time)}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {paragraph}{Effizienz-Ranking}{34}{paragraph*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reverse-Transfer Performance-Paradox}{34}{paragraph*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {F.2}Real-World Deployment Considerations}{35}{subsection.F.2}\protected@file@percent }
\newlabel{app:deployment}{{F.2}{35}{Real-World Deployment Considerations}{subsection.F.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Deployment-Szenarien und Modellempfehlungen}}{35}{table.caption.34}\protected@file@percent }
\newlabel{tab:deployment}{{2}{35}{Deployment-Szenarien und Modellempfehlungen}{table.caption.34}{}}
\expandafter\ifx\csname c@figure@totc\endcsname\relax\newcounter{figure@totc}\fi\setcounter{figure@totc}{20}
\expandafter\ifx\csname c@table@totc\endcsname\relax\newcounter{table@totc}\fi\setcounter{table@totc}{2}
\@writefile{toc}{\contentsline {section}{\numberline {G}Comprehensive Model Dashboard}{36}{appendix.G}\protected@file@percent }
\newlabel{app:dashboard}{{G}{36}{Comprehensive Model Dashboard}{appendix.G}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum.}}{36}{figure.caption.35}\protected@file@percent }
\newlabel{fig:app_dashboard}{{20}{36}{Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum}{figure.caption.35}{}}
\@writefile{toc}{\contentsline {paragraph}{Cluster-Analyse-Befunde}{36}{paragraph*.36}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{B655E040D140ED607B7025E35B82F8D5}
\abx@aux@defaultrefcontext{0}{Belavagi2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Bishop2006}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{CICIDS2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{NSLKDD2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gharib2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Goodfellow2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hastie2009}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{McHugh2000}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Mourouzis2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Platt1999}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Ring2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Sharafaldin2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Taman2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Tavallaee2009}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Vinayakumar2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{GlobalRisksReport2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Zhou2020}{nyt/global//global/global}
\gdef \@abspage@last{42}
