\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\babel@aux{english}{}
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{Abbildungsverzeichnis}{IV}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Tabellenverzeichnis}{V}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Abkürzungsverzeichnis}{VI}{Doc-Start}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{GlobalRisksReport2024}
\abx@aux@segm{0}{0}{GlobalRisksReport2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{GlobalRisksReport2024}
\abx@aux@segm{0}{0}{GlobalRisksReport2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Taman2024}
\abx@aux@segm{0}{0}{Taman2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\abx@aux@cite{0}{Sharafaldin2018}
\abx@aux@segm{0}{0}{Sharafaldin2018}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Mourouzis2021}
\abx@aux@segm{0}{0}{Mourouzis2021}
\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation und Problemstellung}{1}{subsection.1.1}\protected@file@percent }
\abx@aux@page{1}{1}
\abx@aux@page{2}{1}
\abx@aux@page{3}{1}
\abx@aux@page{4}{1}
\abx@aux@page{5}{1}
\abx@aux@page{6}{1}
\abx@aux@page{7}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Forschungsfrage und Zielsetzung}{1}{subsection.1.2}\protected@file@percent }
\abx@aux@page{8}{1}
\abx@aux@page{9}{1}
\abx@aux@page{10}{1}
\abx@aux@page{11}{1}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{McHugh2000}
\abx@aux@segm{0}{0}{McHugh2000}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Aufbau der Arbeit}{2}{subsection.1.3}\protected@file@percent }
\abx@aux@page{12}{2}
\abx@aux@page{13}{2}
\abx@aux@page{14}{2}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Gharib2016}
\abx@aux@segm{0}{0}{Gharib2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@cite{0}{Belavagi2016}
\abx@aux@segm{0}{0}{Belavagi2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretische Fundierung}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Grundlagen der Netzwerk-Anomalieerkennung und Intrusion Detection Systems}{3}{subsection.2.1}\protected@file@percent }
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\abx@aux@page{18}{3}
\abx@aux@page{19}{3}
\abx@aux@page{20}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Traditionelle versus Machine Learning-basierte Detektionsansätze}{3}{subsection.2.2}\protected@file@percent }
\abx@aux@page{21}{3}
\abx@aux@page{22}{3}
\abx@aux@page{23}{3}
\abx@aux@page{24}{3}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Vinayakumar2019}
\abx@aux@segm{0}{0}{Vinayakumar2019}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Bishop2006}
\abx@aux@segm{0}{0}{Bishop2006}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Platt1999}
\abx@aux@segm{0}{0}{Platt1999}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Hastie2009}
\abx@aux@segm{0}{0}{Hastie2009}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@page{25}{4}
\abx@aux@page{26}{4}
\abx@aux@page{27}{4}
\abx@aux@page{28}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Machine Learning-Taxonomie für Anomalieerkennung}{4}{subsection.2.3}\protected@file@percent }
\abx@aux@page{29}{4}
\abx@aux@page{30}{4}
\abx@aux@page{31}{4}
\abx@aux@page{32}{4}
\abx@aux@page{33}{4}
\abx@aux@page{34}{4}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Goodfellow2016}
\abx@aux@segm{0}{0}{Goodfellow2016}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{Ring2019}
\abx@aux@segm{0}{0}{Ring2019}
\abx@aux@page{35}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Transfer Learning und Cross-Dataset-Generalisierung}{5}{subsection.2.4}\protected@file@percent }
\abx@aux@page{36}{5}
\abx@aux@page{37}{5}
\abx@aux@page{38}{5}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodik}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Daten}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Modelle und Hyperparameter}{7}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Beispielhafte Hyperparameter.}}{7}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:hyper}{{1}{7}{Beispielhafte Hyperparameter}{table.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Ergebnisse}{8}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot).}}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:performance_comparison}{{1}{8}{Vergleichende Modellperformance NSL-KDD vs. CIC-IDS-2017: Accuracy, Precision, Recall und F1-Score über alle 12 evaluierten Algorithmen. Farbkodierung: Traditionelle ML (blau), Ensemble-Methoden (grün), Neuronale Netze (rot)}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence.}}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:transfer_analysis}{{2}{9}{Bidirektionale Cross-Dataset-Transfer-Analyse: Performance-Degradation beim Transfer NSL-KDD $\leftrightarrow $ CIC-IDS-2017. Balken zeigen Generalization Gap, Fehlerbalken indizieren Wasserstein Domain Divergence}{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Top-22 Machine Learning Models Performance Ranking: NSL-KDD Dataset}}{9}{table.caption.4}\protected@file@percent }
\newlabel{tab:model_performance}{{2}{9}{Top-22 Machine Learning Models Performance Ranking: NSL-KDD Dataset}{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05).}}{10}{figure.caption.5}\protected@file@percent }
\newlabel{fig:dataset_overview}{{3}{10}{Dataset-spezifische Performance-Charakteristika: (a) Accuracy-Scatter NSL-KDD vs. CIC, (b) Metrik-Boxplots, (c) Statistische Signifikanztests (p < 0.05)}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{11}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Fazit}{12}{section.6}\protected@file@percent }
\abx@aux@page{39}{13}
\abx@aux@page{40}{13}
\abx@aux@page{41}{13}
\abx@aux@page{42}{13}
\abx@aux@page{43}{13}
\abx@aux@page{44}{13}
\abx@aux@page{45}{13}
\abx@aux@page{46}{13}
\abx@aux@page{47}{13}
\abx@aux@page{48}{13}
\abx@aux@page{49}{13}
\abx@aux@page{50}{13}
\abx@aux@page{51}{13}
\abx@aux@page{52}{14}
\abx@aux@page{53}{14}
\@writefile{toc}{\contentsline {section}{Anhangsverzeichnis}{15}{section.6}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{NSLKDD2024}
\abx@aux@segm{0}{0}{NSLKDD2024}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{CICIDS2017}
\abx@aux@segm{0}{0}{CICIDS2017}
\@writefile{toc}{\contentsline {section}{\numberline {A}Dataset-Charakterisierung und Explorative Analyse}{16}{appendix.A}\protected@file@percent }
\newlabel{app:dataset_analysis}{{A}{16}{Dataset-Charakterisierung und Explorative Analyse}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}NSL-KDD Attack Distribution}{16}{subsection.A.1}\protected@file@percent }
\newlabel{app:nsl_attack_dist}{{A.1}{16}{NSL-KDD Attack Distribution}{subsection.A.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle.}}{16}{figure.caption.6}\protected@file@percent }
\newlabel{fig:nsl_attack_dist}{{4}{16}{NSL-KDD Attack-Verteilung und Datensatz-Statistiken: (a) Attack-Kategorie-Verteilung (DoS: 36\%, Probe: 11\%, R2L: <1\%, U2R: <1\%), (b) Training vs. Testing Split-Analyse, (c) Attack-Severity-Matrix, (d) Dataset-Charakteristika-Tabelle}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation der Attack-Verteilung}{16}{paragraph*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}CIC-IDS-2017 Attack Distribution}{17}{subsection.A.2}\protected@file@percent }
\newlabel{app:cic_attack_dist}{{A.2}{17}{CIC-IDS-2017 Attack Distribution}{subsection.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD.}}{17}{figure.caption.8}\protected@file@percent }
\newlabel{fig:cic_attack_dist}{{5}{17}{CIC-IDS-2017 Attack-Verteilung und Temporal Patterns: (a) Moderne Attack-Type-Verteilung (14 Kategorien), (b) Temporal Attack Patterns über 5 Tage (3.-7. Juli 2017), (c) Attack-Severity-Heatmap, (d) Vergleichstabelle mit NSL-KDD}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Unterschiede zu NSL-KDD}{17}{paragraph*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Dataset Comparison Overview}{18}{subsection.A.3}\protected@file@percent }
\newlabel{app:dataset_comparison}{{A.3}{18}{Dataset Comparison Overview}{subsection.A.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148).}}{18}{figure.caption.10}\protected@file@percent }
\newlabel{fig:app_dataset_comparison}{{6}{18}{Vergleichende Dataset-Analyse: (a) Accuracy-Korrelation NSL-KDD vs. CIC (Pearson r = 0.72, p < 0.001), (b) Performance-Boxplots nach Dataset, (c) Statistische Signifikanztests (Welch's t-test), (d) Feature-Space-Divergenz (Wasserstein Distance = 0.148)}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Within-Dataset Performance Details}{19}{appendix.B}\protected@file@percent }
\newlabel{app:within_dataset}{{B}{19}{Within-Dataset Performance Details}{appendix.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}NSL-KDD ROC-Kurven}{19}{subsection.B.1}\protected@file@percent }
\newlabel{app:nsl_roc}{{B.1}{19}{NSL-KDD ROC-Kurven}{subsection.B.1}{}}
\newlabel{fig:nsl_roc_baseline}{{7a}{19}{Baseline-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{sub@fig:nsl_roc_baseline}{{a}{19}{Baseline-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{fig:nsl_roc_advanced}{{7b}{19}{Advanced-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\newlabel{sub@fig:nsl_roc_advanced}{{b}{19}{Advanced-Modelle (6 Algorithmen)}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5).}}{19}{figure.caption.11}\protected@file@percent }
\newlabel{fig:app_nsl_roc}{{7}{19}{ROC-Kurven NSL-KDD: (a) Baseline zeigt moderate Trennschärfe (AUC 0.35--1.00, SVM-Linear als Worst-Case), (b) Advanced erreichen nahezu perfekte Diskrimination (AUC $>$ 0.999 für XGBoost, LightGBM, Gradient Boosting). Diagonale = Random Classifier (AUC 0.5)}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{ROC-Interpretation}{19}{paragraph*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}CIC-IDS-2017 ROC-Kurven}{20}{subsection.B.2}\protected@file@percent }
\newlabel{app:cic_roc}{{B.2}{20}{CIC-IDS-2017 ROC-Kurven}{subsection.B.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren).}}{20}{figure.caption.13}\protected@file@percent }
\newlabel{fig:app_cic_roc}{{8}{20}{ROC-Kurven CIC-IDS-2017: Vergleichbare AUC-Werte wie NSL-KDD, jedoch flacherer Anstieg bei niedrigen FPR-Werten aufgrund höherer Datensatz-Komplexität (79 Features vs. 41, moderne Attack-Vektoren)}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Precision-Recall Kurven}{21}{subsection.B.3}\protected@file@percent }
\newlabel{app:pr_curves}{{B.3}{21}{Precision-Recall Kurven}{subsection.B.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen.}}{21}{figure.caption.14}\protected@file@percent }
\newlabel{fig:app_pr_curves}{{9}{21}{Precision-Recall Trade-Off-Analyse: PR-Kurven sind besonders informativ bei Klassenimbalance (CIC: 83\% Normal). Average Precision (AP) aggregiert Performance über alle Schwellenwerte. Baseline-Modelle zeigen stärkeren Precision-Drop bei hohem Recall (rechte Kurvenabschnitte) im Vergleich zu Advanced-Modellen}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{PR-Kurven vs. ROC-Kurven}{21}{paragraph*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Konfusionsmatrizen NSL-KDD}{22}{subsection.B.4}\protected@file@percent }
\newlabel{app:cm_nsl}{{B.4}{22}{Konfusionsmatrizen NSL-KDD}{subsection.B.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte).}}{22}{figure.caption.16}\protected@file@percent }
\newlabel{fig:app_cm_nsl}{{10}{22}{Konfusionsmatrizen NSL-KDD (normalisiert pro True Label): Diagonalelemente = korrekte Klassifikationen (idealer Wert: 1.0). SVM-Linear zeigt starke False-Negative-Rate (dunklere Off-Diagonal-Werte)}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.5}Konfusionsmatrizen CIC-IDS-2017}{22}{subsection.B.5}\protected@file@percent }
\newlabel{app:cm_cic}{{B.5}{22}{Konfusionsmatrizen CIC-IDS-2017}{subsection.B.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0).}}{22}{figure.caption.17}\protected@file@percent }
\newlabel{fig:app_cm_cic}{{11}{22}{Konfusionsmatrizen CIC-IDS-2017: Naive Bayes zeigt charakteristische Bias zur Attack-Klasse (hohe False-Positive-Rate bei Normal $\rightarrow $ Attack), während Decision Tree nahezu perfekte Klassifikation erreicht (Diagonale $\approx $ 1.0)}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Cross-Validation und Statistische Analysen}{23}{appendix.C}\protected@file@percent }
\newlabel{app:cross_validation}{{C}{23}{Cross-Validation und Statistische Analysen}{appendix.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Cross-Validation Vergleich}{23}{subsection.C.1}\protected@file@percent }
\newlabel{app:cv_comparison}{{C.1}{23}{Cross-Validation Vergleich}{subsection.C.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds.}}{23}{figure.caption.18}\protected@file@percent }
\newlabel{fig:app_cv_comparison}{{12}{23}{Cross-Validation Performance-Vergleich NSL-KDD vs. CIC-IDS-2017: 5-Fold stratifizierte CV mit Konfidenzintervallen (95\% CI). Fehlerbalken indizieren Variabilität über Folds}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}CV Results Distribution}{24}{subsection.C.2}\protected@file@percent }
\newlabel{app:cv_boxplot}{{C.2}{24}{CV Results Distribution}{subsection.C.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83).}}{24}{figure.caption.19}\protected@file@percent }
\newlabel{fig:app_cv_boxplot}{{13}{24}{Boxplot-Verteilung der Cross-Validation Accuracy: Median (zentrale Linie), Interquartilbereich (Box), Whiskers (1.5×IQR), Ausreißer (Punkte). SVM-Linear zeigt extreme Variabilität über Folds (IQR = 0.43, Range = 0.33--0.83)}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {paragraph}{Variabilitäts-Interpretation}{24}{paragraph*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Statistische Vergleichsanalysen}{25}{subsection.C.3}\protected@file@percent }
\newlabel{app:statistical_comparison}{{C.3}{25}{Statistische Vergleichsanalysen}{subsection.C.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05).}}{25}{figure.caption.21}\protected@file@percent }
\newlabel{fig:app_statistical}{{14}{25}{Statistische Vergleichsanalyse Top-5 Modelle: Pairwise t-Tests mit Bonferroni-Korrektur ($\alpha = 0.01$). Heatmap zeigt p-Werte, Sterne indizieren Signifikanz (*** p < 0.001, ** p < 0.01, * p < 0.05)}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Signifikanz-Befunde}{25}{paragraph*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Konvergenzanalyse}{26}{subsection.C.4}\protected@file@percent }
\newlabel{app:convergence}{{C.4}{26}{Konvergenzanalyse}{subsection.C.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean.}}{26}{figure.caption.23}\protected@file@percent }
\newlabel{fig:app_convergence}{{15}{26}{Cross-Validation Konvergenzanalyse: Kumulative Mean Accuracy $\pm $ SD über Folds 1--5. Konvergenz ab Fold 3 indiziert ausreichende k-Wahl. Gestrichelte Linie = finale 5-Fold Mean}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Konvergenz-Interpretation}{26}{paragraph*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D}Cross-Dataset Transfer und Generalisierung}{27}{appendix.D}\protected@file@percent }
\newlabel{app:transfer_analysis}{{D}{27}{Cross-Dataset Transfer und Generalisierung}{appendix.D}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Cross-Dataset Transfer Confusion Matrices}{27}{subsection.D.1}\protected@file@percent }
\newlabel{app:transfer_cm}{{D.1}{27}{Cross-Dataset Transfer Confusion Matrices}{subsection.D.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431).}}{27}{figure.caption.25}\protected@file@percent }
\newlabel{fig:app_transfer_cm}{{16}{27}{Transfer-Learning Konfusionsmatrizen: (a) NSL-KDD $\rightarrow $ CIC-IDS-2017, (b) CIC-IDS-2017 $\rightarrow $ NSL-KDD für XGBoost. Forward-Transfer (a) zeigt moderate Generalisierung (Target Acc = 0.827), Reverse-Transfer (b) zeigt starke Degradation (Target Acc = 0.431)}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Transfer-Pattern-Analyse}{27}{paragraph*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Harmonisierte Evaluation}{28}{subsection.D.2}\protected@file@percent }
\newlabel{app:harmonized}{{D.2}{28}{Harmonisierte Evaluation}{subsection.D.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten).}}{28}{figure.caption.27}\protected@file@percent }
\newlabel{fig:app_harmonized}{{17}{28}{Harmonisierte Cross-Dataset Evaluation: Performance bei PCA-alignierten Features (20 Komponenten, 94.7\% erklärte Varianz). Threshold-Tuning via Grid Search (0.1--0.9 in 0.1-Schritten)}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Harmonisierungs-Effekte}{28}{paragraph*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}Learning Curves und Trainingsanalysen}{29}{appendix.E}\protected@file@percent }
\newlabel{app:learning_curves}{{E}{29}{Learning Curves und Trainingsanalysen}{appendix.E}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Model Learning Curves}{29}{subsection.E.1}\protected@file@percent }
\newlabel{app:learning_curves_detail}{{E.1}{29}{Model Learning Curves}{subsection.E.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen.}}{29}{figure.caption.29}\protected@file@percent }
\newlabel{fig:app_learning_curves}{{18}{29}{Lernkurven Top-3 Modelle bei variierenden Trainingsdatengrößen (1k--100k Samples): Training Accuracy (durchgezogene Linie) vs. Validation Accuracy (gestrichelt). Schattierte Bereiche = 95\% CI über 3 Wiederholungen}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Lernkurven-Interpretation}{29}{paragraph*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Praktische Implikationen}{30}{paragraph*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {F}Computational Efficiency Analysis}{31}{appendix.F}\protected@file@percent }
\newlabel{app:efficiency}{{F}{31}{Computational Efficiency Analysis}{appendix.F}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F.1}Timing Performance Analysis}{31}{subsection.F.1}\protected@file@percent }
\newlabel{app:timing_analysis}{{F.1}{31}{Timing Performance Analysis}{subsection.F.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time).}}{31}{figure.caption.32}\protected@file@percent }
\newlabel{fig:app_timing}{{19}{31}{Training Time vs. Accuracy Trade-Off: Bubble-Chart mit Bubble-Größe proportional zu Inferenzzeit. Optimale Modelle in oberer linker Region (hohe Accuracy, niedrige Training Time)}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Effizienz-Ranking}{31}{paragraph*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reverse-Transfer Performance-Paradox}{31}{paragraph*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {F.2}Real-World Deployment Considerations}{32}{subsection.F.2}\protected@file@percent }
\newlabel{app:deployment}{{F.2}{32}{Real-World Deployment Considerations}{subsection.F.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Deployment-Szenarien und Modellempfehlungen}}{32}{table.caption.35}\protected@file@percent }
\newlabel{tab:deployment}{{3}{32}{Deployment-Szenarien und Modellempfehlungen}{table.caption.35}{}}
\expandafter\ifx\csname c@figure@totc\endcsname\relax\newcounter{figure@totc}\fi\setcounter{figure@totc}{20}
\expandafter\ifx\csname c@table@totc\endcsname\relax\newcounter{table@totc}\fi\setcounter{table@totc}{3}
\@writefile{toc}{\contentsline {section}{\numberline {G}Comprehensive Model Dashboard}{33}{appendix.G}\protected@file@percent }
\newlabel{app:dashboard}{{G}{33}{Comprehensive Model Dashboard}{appendix.G}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum.}}{33}{figure.caption.36}\protected@file@percent }
\newlabel{fig:app_dashboard}{{20}{33}{Comprehensive Multi-Metrik Dashboard: (a) Radar-Chart aller Performance-Metriken, (b) Parallel-Koordinaten-Plot für Metrik-Interaktion, (c) Hierarchische Clustering-Dendrogram ähnlicher Modelle, (d) Principal Component Biplot für Modell-Distanzen im Metrik-Raum}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Cluster-Analyse-Befunde}{33}{paragraph*.37}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{B26DBA847F7CE5F87001434052639395}
\abx@aux@defaultrefcontext{0}{Belavagi2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Bishop2006}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{CICIDS2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{NSLKDD2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Gharib2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Goodfellow2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Hastie2009}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{McHugh2000}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Mourouzis2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Platt1999}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Ring2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Sharafaldin2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Taman2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Vinayakumar2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{GlobalRisksReport2024}{nyt/global//global/global}
\gdef \@abspage@last{40}
