{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e974d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# NSL-KDD Dataset Exploration\\n',\n",
       "    '\\n',\n",
       "    'Comprehensive analysis of the NSL-KDD intrusion detection dataset.\\n',\n",
       "    '\\n',\n",
       "    '## Objectives\\n',\n",
       "    '1. Load and explore the NSL-KDD dataset\\n',\n",
       "    '2. Understand feature distributions and characteristics\\n',\n",
       "    '3. Analyze attack patterns and class distributions\\n',\n",
       "    '4. Identify data quality issues and preprocessing needs\\n',\n",
       "    '5. Generate insights for model development']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Import libraries\\n',\n",
       "    'import sys\\n',\n",
       "    'import os\\n',\n",
       "    \"sys.path.append('../src')\\n\",\n",
       "    '\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    'from nsl_kdd_analyzer import NSLKDDAnalyzer\\n',\n",
       "    '\\n',\n",
       "    '# Set up plotting\\n',\n",
       "    \"plt.style.use('default')\\n\",\n",
       "    'sns.set_palette(\"husl\")\\n',\n",
       "    '%matplotlib inline\\n',\n",
       "    '\\n',\n",
       "    '# Suppress warnings\\n',\n",
       "    'import warnings\\n',\n",
       "    \"warnings.filterwarnings('ignore')\\n\",\n",
       "    '\\n',\n",
       "    'print(\"ðŸ“Š NSL-KDD Analysis Environment Ready!\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Initialize Analyzer and Load Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Initialize the analyzer\\n',\n",
       "    'analyzer = NSLKDDAnalyzer(data_dir=\"../data/raw\", output_dir=\"../data/results\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"Available data files:\")\\n',\n",
       "    'for file in analyzer.data_dir.glob(\"*.txt\"):\\n',\n",
       "    '    size_mb = file.stat().st_size / (1024 * 1024)\\n',\n",
       "    '    print(f\"  ðŸ“„ {file.name:<25} ({size_mb:.1f} MB)\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Quick Analysis with 20% Subset']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Start with 20% subset for faster analysis\\n',\n",
       "    'print(\"ðŸ” Analyzing 20% Training Subset...\")\\n',\n",
       "    \"train_20_data = analyzer.load_data('KDDTrain+_20Percent.txt')\\n\",\n",
       "    '\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    print(f\"\\\\nðŸ“Š Dataset Overview:\")\\n',\n",
       "    '    print(f\"   Shape: {train_20_data.shape}\")\\n',\n",
       "    '    print(f\"   Records: {len(train_20_data):,}\")\\n',\n",
       "    '    print(f\"   Features: {train_20_data.shape[1] - 2}\")\\n',\n",
       "    '    \\n',\n",
       "    '    # Display first few rows\\n',\n",
       "    '    print(f\"\\\\nðŸ“‹ Sample Data:\")\\n',\n",
       "    '    display(train_20_data.head())']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 3. Attack Distribution Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Attack category analysis\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    print(\"ðŸŽ¯ Attack Category Analysis:\")\\n',\n",
       "    \"    attack_summary = train_20_data['attack_category'].value_counts()\\n\",\n",
       "    '    print(attack_summary)\\n',\n",
       "    '    \\n',\n",
       "    '    # Calculate percentages\\n',\n",
       "    '    attack_percentages = (attack_summary / len(train_20_data) * 100).round(2)\\n',\n",
       "    '    print(\"\\\\nPercentages:\")\\n',\n",
       "    '    for category, percentage in attack_percentages.items():\\n',\n",
       "    '        print(f\"  {category}: {percentage}%\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Detailed attack type analysis\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    print(\"ðŸ” Detailed Attack Types:\")\\n',\n",
       "    \"    attack_details = train_20_data.groupby(['attack_category', 'attack_type']).size().reset_index(name='count')\\n\",\n",
       "    \"    attack_details['percentage'] = (attack_details['count'] / len(train_20_data) * 100).round(3)\\n\",\n",
       "    \"    display(attack_details.sort_values('count', ascending=False))\"]},\n",
       "  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 4. Visualization']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Create visualizations\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n',\n",
       "    '    \\n',\n",
       "    '    # Attack categories pie chart\\n',\n",
       "    \"    attack_cat_counts = train_20_data['attack_category'].value_counts()\\n\",\n",
       "    \"    axes[0, 0].pie(attack_cat_counts.values, labels=attack_cat_counts.index, autopct='%1.1f%%', startangle=90)\\n\",\n",
       "    \"    axes[0, 0].set_title('Attack Categories Distribution')\\n\",\n",
       "    '    \\n',\n",
       "    '    # Attack categories bar chart (log scale)\\n',\n",
       "    \"    attack_cat_counts.plot(kind='bar', ax=axes[0, 1], alpha=0.7, logy=True)\\n\",\n",
       "    \"    axes[0, 1].set_title('Attack Categories (Log Scale)')\\n\",\n",
       "    \"    axes[0, 1].set_ylabel('Count (log scale)')\\n\",\n",
       "    \"    axes[0, 1].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '    \\n',\n",
       "    '    # Top 20 attack types\\n',\n",
       "    \"    top_attacks = train_20_data['attack_type'].value_counts().head(20)\\n\",\n",
       "    \"    top_attacks.plot(kind='bar', ax=axes[1, 0], alpha=0.7)\\n\",\n",
       "    \"    axes[1, 0].set_title('Top 20 Attack Types')\\n\",\n",
       "    \"    axes[1, 0].set_ylabel('Count')\\n\",\n",
       "    \"    axes[1, 0].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '    \\n',\n",
       "    '    # Binary classification (Normal vs Attack)\\n',\n",
       "    \"    binary_dist = train_20_data['attack_type'].apply(lambda x: 'Normal' if x == 'normal' else 'Attack').value_counts()\\n\",\n",
       "    \"    binary_dist.plot(kind='bar', ax=axes[1, 1], alpha=0.7, color=['green', 'red'])\\n\",\n",
       "    \"    axes[1, 1].set_title('Binary Classification Distribution')\\n\",\n",
       "    \"    axes[1, 1].set_ylabel('Count')\\n\",\n",
       "    \"    axes[1, 1].tick_params(axis='x', rotation=45)\\n\",\n",
       "    '    \\n',\n",
       "    '    plt.tight_layout()\\n',\n",
       "    '    plt.show()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 5. Feature Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Analyze numerical features\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    numerical_cols = train_20_data.select_dtypes(include=[np.number]).columns.tolist()\\n',\n",
       "    '    # Remove labels\\n',\n",
       "    \"    numerical_cols = [col for col in numerical_cols if col not in ['difficulty_level']]\\n\",\n",
       "    '    \\n',\n",
       "    '    print(f\"ðŸ“Š Numerical Features: {len(numerical_cols)}\")\\n',\n",
       "    '    print(f\"First 10: {numerical_cols[:10]}\")\\n',\n",
       "    '    \\n',\n",
       "    '    # Statistical summary for key features\\n',\n",
       "    \"    key_features = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\\n\",\n",
       "    '    print(f\"\\\\nðŸ“ˆ Key Features Statistics:\")\\n',\n",
       "    '    display(train_20_data[key_features].describe())']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 6. Next Steps and Insights']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Summary and next steps\\n',\n",
       "    'if train_20_data is not None:\\n',\n",
       "    '    print(\"ðŸŽ¯ KEY INSIGHTS:\")\\n',\n",
       "    '    print(\"=\"*50)\\n',\n",
       "    '    \\n',\n",
       "    \"    normal_pct = (train_20_data['attack_type'] == 'normal').mean() * 100\\n\",\n",
       "    '    attack_pct = 100 - normal_pct\\n',\n",
       "    '    \\n',\n",
       "    '    print(f\"1. Dataset Characteristics:\")\\n',\n",
       "    '    print(f\"   â€¢ Records: {len(train_20_data):,}\")\\n',\n",
       "    '    print(f\"   â€¢ Features: {train_20_data.shape[1] - 2}\")\\n',\n",
       "    '    print(f\"   â€¢ Attack types: {train_20_data[\\'attack_type\\'].nunique()}\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(f\"\\\\n2. Class Distribution:\")\\n',\n",
       "    '    print(f\"   â€¢ Normal traffic: {normal_pct:.1f}%\")\\n',\n",
       "    '    print(f\"   â€¢ Attack traffic: {attack_pct:.1f}%\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(f\"\\\\n3. Key Challenges:\")\\n',\n",
       "    '    print(f\"   â€¢ Severe class imbalance\")\\n',\n",
       "    '    print(f\"   â€¢ Mixed data types (numerical + categorical)\")\\n',\n",
       "    '    print(f\"   â€¢ High dimensionality (41 features)\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(f\"\\\\n4. Next Steps:\")\\n',\n",
       "    '    print(f\"   â€¢ Create preprocessing pipeline\")\\n',\n",
       "    '    print(f\"   â€¢ Handle class imbalance\")\\n',\n",
       "    '    print(f\"   â€¢ Implement baseline models\")\\n',\n",
       "    '    print(f\"   â€¢ Set up evaluation framework\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(f\"\\\\nâœ… Exploration complete! Ready for preprocessing phase.\")']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.9.0'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# NSL-KDD Dataset Exploration\\n\",\n",
    "    \"\\n\",\n",
    "    \"Comprehensive analysis of the NSL-KDD intrusion detection dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objectives\\n\",\n",
    "    \"1. Load and explore the NSL-KDD dataset\\n\",\n",
    "    \"2. Understand feature distributions and characteristics\\n\",\n",
    "    \"3. Analyze attack patterns and class distributions\\n\",\n",
    "    \"4. Identify data quality issues and preprocessing needs\\n\",\n",
    "    \"5. Generate insights for model development\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from nsl_kdd_analyzer import NSLKDDAnalyzer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up plotting\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Suppress warnings\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"ðŸ“Š NSL-KDD Analysis Environment Ready!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Initialize Analyzer and Load Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize the analyzer\\n\",\n",
    "    \"analyzer = NSLKDDAnalyzer(data_dir=\\\"../data/raw\\\", output_dir=\\\"../data/results\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Available data files:\\\")\\n\",\n",
    "    \"for file in analyzer.data_dir.glob(\\\"*.txt\\\"):\\n\",\n",
    "    \"    size_mb = file.stat().st_size / (1024 * 1024)\\n\",\n",
    "    \"    print(f\\\"  ðŸ“„ {file.name:<25} ({size_mb:.1f} MB)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Quick Analysis with 20% Subset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Start with 20% subset for faster analysis\\n\",\n",
    "    \"print(\\\"ðŸ” Analyzing 20% Training Subset...\\\")\\n\",\n",
    "    \"train_20_data = analyzer.load_data('KDDTrain+_20Percent.txt')\\n\",\n",
    "    \"\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    print(f\\\"\\\\nðŸ“Š Dataset Overview:\\\")\\n\",\n",
    "    \"    print(f\\\"   Shape: {train_20_data.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"   Records: {len(train_20_data):,}\\\")\\n\",\n",
    "    \"    print(f\\\"   Features: {train_20_data.shape[1] - 2}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display first few rows\\n\",\n",
    "    \"    print(f\\\"\\\\nðŸ“‹ Sample Data:\\\")\\n\",\n",
    "    \"    display(train_20_data.head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Attack Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Attack category analysis\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    print(\\\"ðŸŽ¯ Attack Category Analysis:\\\")\\n\",\n",
    "    \"    attack_summary = train_20_data['attack_category'].value_counts()\\n\",\n",
    "    \"    print(attack_summary)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate percentages\\n\",\n",
    "    \"    attack_percentages = (attack_summary / len(train_20_data) * 100).round(2)\\n\",\n",
    "    \"    print(\\\"\\\\nPercentages:\\\")\\n\",\n",
    "    \"    for category, percentage in attack_percentages.items():\\n\",\n",
    "    \"        print(f\\\"  {category}: {percentage}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Detailed attack type analysis\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    print(\\\"ðŸ” Detailed Attack Types:\\\")\\n\",\n",
    "    \"    attack_details = train_20_data.groupby(['attack_category', 'attack_type']).size().reset_index(name='count')\\n\",\n",
    "    \"    attack_details['percentage'] = (attack_details['count'] / len(train_20_data) * 100).round(3)\\n\",\n",
    "    \"    display(attack_details.sort_values('count', ascending=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create visualizations\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Attack categories pie chart\\n\",\n",
    "    \"    attack_cat_counts = train_20_data['attack_category'].value_counts()\\n\",\n",
    "    \"    axes[0, 0].pie(attack_cat_counts.values, labels=attack_cat_counts.index, autopct='%1.1f%%', startangle=90)\\n\",\n",
    "    \"    axes[0, 0].set_title('Attack Categories Distribution')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Attack categories bar chart (log scale)\\n\",\n",
    "    \"    attack_cat_counts.plot(kind='bar', ax=axes[0, 1], alpha=0.7, logy=True)\\n\",\n",
    "    \"    axes[0, 1].set_title('Attack Categories (Log Scale)')\\n\",\n",
    "    \"    axes[0, 1].set_ylabel('Count (log scale)')\\n\",\n",
    "    \"    axes[0, 1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Top 20 attack types\\n\",\n",
    "    \"    top_attacks = train_20_data['attack_type'].value_counts().head(20)\\n\",\n",
    "    \"    top_attacks.plot(kind='bar', ax=axes[1, 0], alpha=0.7)\\n\",\n",
    "    \"    axes[1, 0].set_title('Top 20 Attack Types')\\n\",\n",
    "    \"    axes[1, 0].set_ylabel('Count')\\n\",\n",
    "    \"    axes[1, 0].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Binary classification (Normal vs Attack)\\n\",\n",
    "    \"    binary_dist = train_20_data['attack_type'].apply(lambda x: 'Normal' if x == 'normal' else 'Attack').value_counts()\\n\",\n",
    "    \"    binary_dist.plot(kind='bar', ax=axes[1, 1], alpha=0.7, color=['green', 'red'])\\n\",\n",
    "    \"    axes[1, 1].set_title('Binary Classification Distribution')\\n\",\n",
    "    \"    axes[1, 1].set_ylabel('Count')\\n\",\n",
    "    \"    axes[1, 1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze numerical features\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    numerical_cols = train_20_data.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "    \"    # Remove labels\\n\",\n",
    "    \"    numerical_cols = [col for col in numerical_cols if col not in ['difficulty_level']]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"ðŸ“Š Numerical Features: {len(numerical_cols)}\\\")\\n\",\n",
    "    \"    print(f\\\"First 10: {numerical_cols[:10]}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Statistical summary for key features\\n\",\n",
    "    \"    key_features = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\\n\",\n",
    "    \"    print(f\\\"\\\\nðŸ“ˆ Key Features Statistics:\\\")\\n\",\n",
    "    \"    display(train_20_data[key_features].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Next Steps and Insights\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Summary and next steps\\n\",\n",
    "    \"if train_20_data is not None:\\n\",\n",
    "    \"    print(\\\"ðŸŽ¯ KEY INSIGHTS:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*50)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    normal_pct = (train_20_data['attack_type'] == 'normal').mean() * 100\\n\",\n",
    "    \"    attack_pct = 100 - normal_pct\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"1. Dataset Characteristics:\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Records: {len(train_20_data):,}\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Features: {train_20_data.shape[1] - 2}\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Attack types: {train_20_data['attack_type'].nunique()}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n2. Class Distribution:\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Normal traffic: {normal_pct:.1f}%\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Attack traffic: {attack_pct:.1f}%\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n3. Key Challenges:\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Severe class imbalance\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Mixed data types (numerical + categorical)\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ High dimensionality (41 features)\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n4. Next Steps:\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Create preprocessing pipeline\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Handle class imbalance\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Implement baseline models\\\")\\n\",\n",
    "    \"    print(f\\\"   â€¢ Set up evaluation framework\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nâœ… Exploration complete! Ready for preprocessing phase.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
